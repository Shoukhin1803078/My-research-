{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF97UQyqY5EwO1Y6p5GN87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shoukhin1803078/My-research-/blob/main/BDMLI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JmSzkdn6wWHJ"
      },
      "outputs": [],
      "source": [
        "#!pip install -q peft\n",
        "#!pip show peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import peft\n",
        "#dir(peft)"
      ],
      "metadata": {
        "id": "irXQFI3ewdRw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes peft trl accelerate torchkeras langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7BopdI4wmaH",
        "outputId": "26a4a7a8-ab9a-4110-8178-aba07460d9ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "#from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from time import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import specific libraries for acceleration and model performance monitoring\n",
        "import accelerate\n",
        "import peft\n",
        "\n",
        "# Import necessary modules from the transformers library\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModel, BitsAndBytesConfig, AutoModelForCausalLM\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "\n",
        "# Set environment variables for PyTorch CUDA and XLA\n",
        "# max_split_size_mb - prevents allocator from splitting blocks larger than this size\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
        "os.environ['XLA_USE_BF16'] = \"1\"\n",
        "os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n",
        "\n",
        "# Import the torchkeras library for enhanced PyTorch functionality\n",
        "import torchkeras\n",
        "\n",
        "time_start = time()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "e9ohfunFwv9m",
        "outputId": "406834b1-f568-4011-ede7-0851b20f51d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n#from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM\\n\\n\\n\\nimport numpy as np\\nimport pandas as pd \\nfrom datasets import load_dataset, Dataset\\nimport torch\\nfrom torch import nn \\nfrom torch.utils.data import DataLoader \\n\\nfrom time import time\\nimport warnings \\nwarnings.filterwarnings(\\'ignore\\')\\n\\n# Import specific libraries for acceleration and model performance monitoring\\nimport accelerate \\nimport peft \\n\\n# Import necessary modules from the transformers library\\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel, BitsAndBytesConfig, AutoModelForCausalLM\\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\\n\\n# Set environment variables for PyTorch CUDA and XLA\\n# max_split_size_mb - prevents allocator from splitting blocks larger than this size\\nimport os\\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\" \\nos.environ[\\'XLA_USE_BF16\\'] = \"1\"\\nos.environ[\\'XLA_TENSOR_ALLOCATOR_MAXSIZE\\'] = \\'100000000\\'\\n\\n# Import the torchkeras library for enhanced PyTorch functionality\\nimport torchkeras\\n\\ntime_start = time()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5b7cRIjwzAF",
        "outputId": "bc6e5f61-1461-460e-beda-19aacbcdc5f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: datasets\n",
            "Version: 2.18.0\n",
            "Summary: HuggingFace community-driven open-source library of datasets\n",
            "Home-page: https://github.com/huggingface/datasets\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyarrow-hotfix, pyyaml, requests, tqdm, xxhash\n",
            "Required-by: trl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQnQew1YxiUC",
        "outputId": "0bbaefee-8a16-4d61-ae4c-d78d8e2bc367"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgOrZWCzx1Qe",
        "outputId": "0642244d-cd97-4e89-aa50-8c775481b234"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from random import randrange\n",
        "from functools import partial\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          HfArgumentParser,\n",
        "                          Trainer,\n",
        "                          TrainingArguments,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          EarlyStoppingCallback,\n",
        "                          pipeline,\n",
        "                          logging,\n",
        "                          set_seed)\n",
        "import bitsandbytes as bnb\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pps_8Y02x5Ng",
        "outputId": "f0311222-14d2-4624-de5a-4cd3969152d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel, AutoPeftModelForCausalLM\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "0P1Zc6wWx-hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset preprocessing\n"
      ],
      "metadata": {
        "id": "4N_9uyVTyePp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Read the first few lines of the file to check the format\n",
        "with open(\"/content/sample_data/News_Category_Dataset_v3.json\", 'r') as file:\n",
        "    for _ in range(5):\n",
        "        print(file.readline())\n",
        "\n",
        "# Initialize an empty list to store the JSON objects\n",
        "data = []\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7GEuUxpyZpx",
        "outputId": "37890415-b1ee-4465-e025-781ff7856cad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"link\": \"https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9\", \"headline\": \"Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\", \"category\": \"U.S. NEWS\", \"short_description\": \"Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\", \"authors\": \"Carla K. Johnson, AP\", \"date\": \"2022-09-23\"}\n",
            "\n",
            "{\"link\": \"https://www.huffpost.com/entry/american-airlines-passenger-banned-flight-attendant-punch-justice-department_n_632e25d3e4b0e247890329fe\", \"headline\": \"American Airlines Flyer Charged, Banned For Life After Punching Flight Attendant On Video\", \"category\": \"U.S. NEWS\", \"short_description\": \"He was subdued by passengers and crew when he fled to the back of the aircraft after the confrontation, according to the U.S. attorney's office in Los Angeles.\", \"authors\": \"Mary Papenfuss\", \"date\": \"2022-09-23\"}\n",
            "\n",
            "{\"link\": \"https://www.huffpost.com/entry/funniest-tweets-cats-dogs-september-17-23_n_632de332e4b0695c1d81dc02\", \"headline\": \"23 Of The Funniest Tweets About Cats And Dogs This Week (Sept. 17-23)\", \"category\": \"COMEDY\", \"short_description\": \"\\\"Until you have a dog you don't understand what could be eaten.\\\"\", \"authors\": \"Elyse Wanshel\", \"date\": \"2022-09-23\"}\n",
            "\n",
            "{\"link\": \"https://www.huffpost.com/entry/funniest-parenting-tweets_l_632d7d15e4b0d12b5403e479\", \"headline\": \"The Funniest Tweets From Parents This Week (Sept. 17-23)\", \"category\": \"PARENTING\", \"short_description\": \"\\\"Accidentally put grown-up toothpaste on my toddler\\u2019s toothbrush and he screamed like I was cleaning his teeth with a Carolina Reaper dipped in Tabasco sauce.\\\"\", \"authors\": \"Caroline Bologna\", \"date\": \"2022-09-23\"}\n",
            "\n",
            "{\"link\": \"https://www.huffpost.com/entry/amy-cooper-loses-discrimination-lawsuit-franklin-templeton_n_632c6463e4b09d8701bd227e\", \"headline\": \"Woman Who Called Cops On Black Bird-Watcher Loses Lawsuit Against Ex-Employer\", \"category\": \"U.S. NEWS\", \"short_description\": \"Amy Cooper accused investment firm Franklin Templeton of unfairly firing her and branding her a racist after video of the Central Park encounter went viral.\", \"authors\": \"Nina Golgowski\", \"date\": \"2022-09-22\"}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data = []\n",
        "\n",
        "with open('/content/sample_data/News_Category_Dataset_v3.json', 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            # Attempt to parse the JSON line\n",
        "            parsed_line = json.loads(line)\n",
        "            data.append(parsed_line)\n",
        "        except json.JSONDecodeError as e:\n",
        "            # Print an error message and continue with the next line\n",
        "            print(f\"Error parsing line: {e}\")\n",
        "            continue\n",
        "\n",
        "raw_news_df = pd.DataFrame(data)\n",
        "print(raw_news_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueW69d0Zz2dk",
        "outputId": "5055b46e-b31b-42cd-b78b-dc84ef40be6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error parsing line: Expecting property name enclosed in double quotes: line 1 column 343 (char 342)\n",
            "                                                link  \\\n",
            "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
            "1  https://www.huffpost.com/entry/american-airlin...   \n",
            "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
            "3  https://www.huffpost.com/entry/funniest-parent...   \n",
            "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
            "\n",
            "                                            headline   category  \\\n",
            "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
            "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
            "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
            "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
            "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
            "\n",
            "                                   short_description               authors  \\\n",
            "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
            "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
            "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
            "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
            "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
            "\n",
            "         date  \n",
            "0  2022-09-23  \n",
            "1  2022-09-23  \n",
            "2  2022-09-23  \n",
            "3  2022-09-23  \n",
            "4  2022-09-22  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_news_df['category'].unique().size)\n",
        "print(raw_news_df['category'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fsRIrKO0Ld4",
        "outputId": "9d72bdac-f2f0-4aaa-fdcd-9daa8f9129f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "['U.S. NEWS' 'COMEDY' 'PARENTING' 'WORLD NEWS' 'CULTURE & ARTS' 'TECH'\n",
            " 'SPORTS' 'ENTERTAINMENT' 'POLITICS' 'WEIRD NEWS' 'ENVIRONMENT'\n",
            " 'EDUCATION' 'CRIME' 'SCIENCE' 'WELLNESS' 'BUSINESS' 'STYLE & BEAUTY'\n",
            " 'FOOD & DRINK' 'MEDIA' 'QUEER VOICES' 'HOME & LIVING' 'WOMEN'\n",
            " 'BLACK VOICES' 'TRAVEL' 'MONEY' 'RELIGION' 'LATINO VOICES' 'IMPACT'\n",
            " 'WEDDINGS' 'COLLEGE' 'PARENTS' 'ARTS & CULTURE' 'STYLE' 'GREEN' 'TASTE'\n",
            " 'HEALTHY LIVING' 'THE WORLDPOST' 'GOOD NEWS' 'WORLDPOST' 'FIFTY' 'ARTS'\n",
            " 'DIVORCE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_news_df['headline'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dReMhklh0ZSl",
        "outputId": "987a62bb-9efc-49d7-97c5-a218b2e44805"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instr_news_df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "vZncCoRP0cJI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instr_news_df['input'] = raw_news_df['headline'].astype(str) + '\\n' + raw_news_df['short_description'].astype(str)\n",
        "instr_news_df['output'] = raw_news_df['category']\n",
        "instr_news_df['instruction'] = 'Categorize the news article description into one of the 42 categories:\\n\\nU.S. NEWS\\nCOMEDY\\nPARENTING\\nWORLD NEWS\\nCULTURE & ARTS\\nTECH\\nSPORTS\\nENTERTAINMENT\\nPOLITICS\\nWEIRD NEWS\\nENVIRONMENT\\nEDUCATION\\nCRIME\\nSCIENCE\\nWELLNESS\\nBUSINESS\\nSTYLE & BEAUTY\\nFOOD & DRINK\\nMEDIA\\nQUEER VOICES\\nHOME & LIVING\\nWOMEN\\nBLACK VOICES\\nTRAVEL\\nMONEY\\nRELIGION\\nLATINO VOICES\\nIMPACT\\nWEDDINGS\\nCOLLEGE\\nPARENTS\\nARTS & CULTURE\\nSTYLE\\nGREEN\\nTASTE\\nHEALTHY LIVING\\nTHE WORLDPOST\\nGOOD NEWS\\nWORLDPOST\\nFIFTY\\nARTS\\nDIVORCE'\n"
      ],
      "metadata": {
        "id": "xxonDIUs0cU2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instr_news_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5czY3wJ50cXZ",
        "outputId": "e2b211e7-c403-47a8-9067-16569ea70a8b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input     output  \\\n",
              "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
              "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
              "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
              "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
              "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
              "\n",
              "                                         instruction  \n",
              "0  Categorize the news article description into o...  \n",
              "1  Categorize the news article description into o...  \n",
              "2  Categorize the news article description into o...  \n",
              "3  Categorize the news article description into o...  \n",
              "4  Categorize the news article description into o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff7ce951-b340-4e1d-8bc2-6a976d90a4be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff7ce951-b340-4e1d-8bc2-6a976d90a4be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff7ce951-b340-4e1d-8bc2-6a976d90a4be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff7ce951-b340-4e1d-8bc2-6a976d90a4be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03476c71-9753-470f-b5a9-8bd476a997d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03476c71-9753-470f-b5a9-8bd476a997d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03476c71-9753-470f-b5a9-8bd476a997d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "instr_news_df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instr_news_df.to_csv(\"news_classification.csv\", index=False)"
      ],
      "metadata": {
        "id": "ERpHs_F00caK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv('news_classification.csv')"
      ],
      "metadata": {
        "id": "9JLNwHVX0mp2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gcZhDB7i0msQ",
        "outputId": "0747873e-7b2e-44a6-d1d6-d6d59935669e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input     output  \\\n",
              "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
              "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
              "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
              "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
              "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
              "\n",
              "                                         instruction  \n",
              "0  Categorize the news article description into o...  \n",
              "1  Categorize the news article description into o...  \n",
              "2  Categorize the news article description into o...  \n",
              "3  Categorize the news article description into o...  \n",
              "4  Categorize the news article description into o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dc61212-d848-4e03-98f2-03ec1bee8fa5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Categorize the news article description into o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dc61212-d848-4e03-98f2-03ec1bee8fa5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dc61212-d848-4e03-98f2-03ec1bee8fa5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dc61212-d848-4e03-98f2-03ec1bee8fa5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-480423fb-55d1-457d-84b3-1b5c7e007e6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-480423fb-55d1-457d-84b3-1b5c7e007e6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-480423fb-55d1-457d-84b3-1b5c7e007e6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news_df"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['input'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "j9qL9di90muX",
        "outputId": "63b4c4b2-2151-4bf7-8aca-9de4adf57222"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\\nHealth experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Setup**\n",
        "\n"
      ],
      "metadata": {
        "id": "sHcAkWsh0wtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_name = \"/kaggle/input/llama-2/pytorch/7b-hf/1\"\n",
        "model_name = \"tiiuae/falcon-7b-instruct\""
      ],
      "metadata": {
        "id": "5-HlSwft0mwH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "time_1 = time()\n",
        "\n",
        "# Set model configuration for Kaggle compatibility\n",
        "model_name_or_path = model_name\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                      # Loads model in 4 bit quantization\n",
        "    bnb_4bit_use_double_quant=True,         # Uses second quantization to save 0.4 bits\n",
        "    bnb_4bit_quant_type=\"nf4\",              # 4-bit NoramlFloat\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,  # Computation still happens in 16 or 32-bit\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "\n",
        ")\n",
        "\n",
        "# Initialize tokenizer with the specified model configuration\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name_or_path, trust_remote_code=True)  # Cache to the current working directory\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Initialize the model with the specified model configuration and device mapping\n",
        "model =  AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map = 'auto')\n",
        "model.config.use_cache = False     # Disable cache for generation\n",
        "model.config.pretraining_tp = 1    # Slower but more accurate computation of linear layers\n",
        "\n",
        "time_2 = time()\n",
        "print(f\"Time elapsed: {round(time_2-time_1, 3)} sec.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "tYZc-14L0mxz",
        "outputId": "ffd06ff1-6117-4f39-9ec3-d73ab586eacf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\ntime_1 = time()\\n\\n# Set model configuration for Kaggle compatibility\\nmodel_name_or_path = model_name\\nbnb_config = BitsAndBytesConfig(\\n    load_in_4bit=True,                      # Loads model in 4 bit quantization\\n    bnb_4bit_use_double_quant=True,         # Uses second quantization to save 0.4 bits\\n    bnb_4bit_quant_type=\"nf4\",              # 4-bit NoramlFloat\\n    bnb_4bit_compute_dtype=torch.bfloat16,  # Computation still happens in 16 or 32-bit\\n    llm_int8_has_fp16_weight=False,\\n        \\n)\\n\\n# Initialize tokenizer with the specified model configuration\\ntokenizer = AutoTokenizer.from_pretrained(\\n    model_name_or_path, trust_remote_code=True)  # Cache to the current working directory\\ntokenizer.pad_token = tokenizer.eos_token\\n\\n# Initialize the model with the specified model configuration and device mapping\\nmodel =  AutoModelForCausalLM.from_pretrained(\\n    model_name_or_path,\\n    quantization_config=bnb_config,\\n    trust_remote_code=True,\\n    low_cpu_mem_usage=True,\\n    device_map = \\'auto\\')  \\nmodel.config.use_cache = False     # Disable cache for generation\\nmodel.config.pretraining_tp = 1    # Slower but more accurate computation of linear layers\\n\\ntime_2 = time()\\nprint(f\"Time elapsed: {round(time_2-time_1, 3)} sec.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Or function defined load model**"
      ],
      "metadata": {
        "id": "3QCh2UyY1Hng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_bnb_config(load_in_4bit, bnb_4bit_use_double_quant, bnb_4bit_quant_type, bnb_4bit_compute_dtype):\n",
        "    \"\"\"\n",
        "    Configures model quantization method using bitsandbytes to speed up training and inference\n",
        "\n",
        "    :param load_in_4bit: Load model in 4-bit precision mode\n",
        "    :param bnb_4bit_use_double_quant: Nested quantization for 4-bit model\n",
        "    :param bnb_4bit_quant_type: Quantization data type for 4-bit model\n",
        "    :param bnb_4bit_compute_dtype: Computation data type for 4-bit model\n",
        "    \"\"\"\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit = load_in_4bit,\n",
        "        bnb_4bit_use_double_quant = bnb_4bit_use_double_quant,\n",
        "        bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
        "        bnb_4bit_compute_dtype = bnb_4bit_compute_dtype,\n",
        "    )\n",
        "\n",
        "    return bnb_config\n",
        "\n",
        "def load_model(model_name, bnb_config):\n",
        "    \"\"\"\n",
        "    Loads model and model tokenizer\n",
        "\n",
        "    :param model_name: Hugging Face model name\n",
        "    :param bnb_config: Bitsandbytes configuration\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    n_gpus = torch.cuda.device_count()\n",
        "    max_memory = f'{40960}MB'\n",
        "\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config = bnb_config,\n",
        "        device_map = \"auto\", # dispatch the model efficiently on the available resources\n",
        "        max_memory = {i: max_memory for i in range(n_gpus)},\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# transformers parameters\n",
        "\n",
        "model_name = model_name\n",
        "\n",
        "\n",
        "\n",
        "load_in_4bit = True\n",
        "\n",
        "\n",
        "bnb_4bit_use_double_quant = True\n",
        "\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "bnb_4bit_compute_dtype = torch.bfloat16\n",
        "\n",
        "\n",
        "\n",
        "bnb_config = create_bnb_config(load_in_4bit, bnb_4bit_use_double_quant, bnb_4bit_quant_type, bnb_4bit_compute_dtype)\n",
        "\n",
        "model, tokenizer = load_model(model_name, bnb_config)"
      ],
      "metadata": {
        "id": "_rXjtfnI1FJl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = load_dataset(\"csv\", data_files='news_classification.csv')\n",
        "from datasets import Dataset\n",
        "news_df = pd.read_csv('news_classification.csv')\n",
        "dataset = Dataset.from_pandas(news_df)\n",
        "\n",
        "print(f'Number of prompts: {len(dataset)}')\n",
        "print(f'Column names are: {dataset.column_names}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hmHnKSC1FMT",
        "outputId": "f200619e-8e93-43f7-fb96-63fa15224345"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of prompts: 134481\n",
            "Column names are: ['input', 'output', 'instruction']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt_formats(sample):\n",
        "    \"\"\"\n",
        "    Creates a formatted prompt template for a prompt in the instruction dataset\n",
        "\n",
        "    :param sample: Prompt or sample from the instruction dataset\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
        "    INSTRUCTION_KEY = \"### Instruction:\"\n",
        "    INPUT_KEY = \"Input:\"\n",
        "    RESPONSE_KEY = \"### Response:\"\n",
        "    END_KEY = \"### End\"\n",
        "\n",
        "    blurb = f\"{INTRO_BLURB}\"\n",
        "    instruction = f\"{INSTRUCTION_KEY}\\n{sample['instruction']}\"\n",
        "    input_context = f\"{INPUT_KEY}\\n{sample['input']}\" if sample[\"input\"] else None\n",
        "    response = f\"{RESPONSE_KEY}\\n{sample['output']}\"\n",
        "    end = f\"{END_KEY}\"\n",
        "\n",
        "    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n",
        "\n",
        "    formatted_prompt = \"\\n\\n\".join(parts)\n",
        "\n",
        "    sample[\"text\"] = formatted_prompt\n",
        "\n",
        "    return sample"
      ],
      "metadata": {
        "id": "hlPS7DOZ1FOt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_prompt_formats(dataset[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oCSBglf1FQ3",
        "outputId": "a05901df-f791-4e27-8613-c006a844f94e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\\nHealth experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.', 'output': 'U.S. NEWS', 'instruction': 'Categorize the news article description into one of the 42 categories:\\n\\nU.S. NEWS\\nCOMEDY\\nPARENTING\\nWORLD NEWS\\nCULTURE & ARTS\\nTECH\\nSPORTS\\nENTERTAINMENT\\nPOLITICS\\nWEIRD NEWS\\nENVIRONMENT\\nEDUCATION\\nCRIME\\nSCIENCE\\nWELLNESS\\nBUSINESS\\nSTYLE & BEAUTY\\nFOOD & DRINK\\nMEDIA\\nQUEER VOICES\\nHOME & LIVING\\nWOMEN\\nBLACK VOICES\\nTRAVEL\\nMONEY\\nRELIGION\\nLATINO VOICES\\nIMPACT\\nWEDDINGS\\nCOLLEGE\\nPARENTS\\nARTS & CULTURE\\nSTYLE\\nGREEN\\nTASTE\\nHEALTHY LIVING\\nTHE WORLDPOST\\nGOOD NEWS\\nWORLDPOST\\nFIFTY\\nARTS\\nDIVORCE', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCategorize the news article description into one of the 42 categories:\\n\\nU.S. NEWS\\nCOMEDY\\nPARENTING\\nWORLD NEWS\\nCULTURE & ARTS\\nTECH\\nSPORTS\\nENTERTAINMENT\\nPOLITICS\\nWEIRD NEWS\\nENVIRONMENT\\nEDUCATION\\nCRIME\\nSCIENCE\\nWELLNESS\\nBUSINESS\\nSTYLE & BEAUTY\\nFOOD & DRINK\\nMEDIA\\nQUEER VOICES\\nHOME & LIVING\\nWOMEN\\nBLACK VOICES\\nTRAVEL\\nMONEY\\nRELIGION\\nLATINO VOICES\\nIMPACT\\nWEDDINGS\\nCOLLEGE\\nPARENTS\\nARTS & CULTURE\\nSTYLE\\nGREEN\\nTASTE\\nHEALTHY LIVING\\nTHE WORLDPOST\\nGOOD NEWS\\nWORLDPOST\\nFIFTY\\nARTS\\nDIVORCE\\n\\nInput:\\nOver 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\\nHealth experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\\n\\n### Response:\\nU.S. NEWS\\n\\n### End'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_length(model):\n",
        "    \"\"\"\n",
        "    Extracts maximum token length from the model configuration\n",
        "\n",
        "    :param model: Hugging Face model\n",
        "    \"\"\"\n",
        "\n",
        "    # Pull model configuration\n",
        "    conf = model.config\n",
        "    # Initialize a \"max_length\" variable to store maximum sequence length as null\n",
        "    max_length = None\n",
        "    # Find maximum sequence length in the model configuration and save it in \"max_length\" if found\n",
        "    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n",
        "        max_length = getattr(model.config, length_setting, None)\n",
        "        if max_length:\n",
        "            print(f\"Found max lenth: {max_length}\")\n",
        "            break\n",
        "    # Set \"max_length\" to 1024 (default value) if maximum sequence length is not found in the model configuration\n",
        "    if not max_length:\n",
        "        max_length = 1024\n",
        "        print(f\"Using default max length: {max_length}\")\n",
        "    return max_length"
      ],
      "metadata": {
        "id": "6LKeA8YS1FSs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_batch(batch, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Tokenizes dataset batch\n",
        "\n",
        "    :param batch: Dataset batch\n",
        "    :param tokenizer: Model tokenizer\n",
        "    :param max_length: Maximum number of tokens to emit from the tokenizer\n",
        "    \"\"\"\n",
        "\n",
        "    return tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length = max_length,\n",
        "        truncation = True,\n",
        "    )"
      ],
      "metadata": {
        "id": "HkDpDYjm1FUl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset: str):\n",
        "    \"\"\"\n",
        "    Tokenizes dataset for fine-tuning\n",
        "\n",
        "    :param tokenizer (AutoTokenizer): Model tokenizer\n",
        "    :param max_length (int): Maximum number of tokens to emit from the tokenizer\n",
        "    :param seed: Random seed for reproducibility\n",
        "    :param dataset (str): Instruction dataset\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    print(\"Preprocessing dataset...\")\n",
        "    dataset = dataset.map(create_prompt_formats)\n",
        "\n",
        "    _preprocessing_function = partial(preprocess_batch, max_length = max_length, tokenizer = tokenizer)\n",
        "    dataset = dataset.map(\n",
        "        _preprocessing_function,\n",
        "        batched = True,\n",
        "        remove_columns = [\"instruction\", \"input\", \"output\", \"text\"],\n",
        "    )\n",
        "\n",
        "\n",
        "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n",
        "\n",
        "\n",
        "    dataset = dataset.shuffle(seed = seed)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "EXWoqlVb1FWh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create peft config**"
      ],
      "metadata": {
        "id": "YGeogg352KkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_peft_config(r, lora_alpha, target_modules, lora_dropout, bias, task_type):\n",
        "    \"\"\"\n",
        "    Creates Parameter-Efficient Fine-Tuning configuration for the model\n",
        "\n",
        "    :param r: LoRA attention dimension\n",
        "    :param lora_alpha: Alpha parameter for LoRA scaling\n",
        "    :param modules: Names of the modules to apply LoRA to\n",
        "    :param lora_dropout: Dropout Probability for LoRA layers\n",
        "    :param bias: Specifies if the bias parameters should be trained\n",
        "    \"\"\"\n",
        "    config = LoraConfig(\n",
        "        r = r,\n",
        "        lora_alpha = lora_alpha,\n",
        "        target_modules = target_modules,\n",
        "        lora_dropout = lora_dropout,\n",
        "        bias = bias,\n",
        "        task_type = task_type,\n",
        "    )\n",
        "\n",
        "    return config\n",
        "\n",
        "def find_all_linear_names(model):\n",
        "    \"\"\"\n",
        "    Find modules to apply LoRA to.\n",
        "\n",
        "    :param model: PEFT model\n",
        "    \"\"\"\n",
        "\n",
        "    cls = bnb.nn.Linear4bit\n",
        "    lora_module_names = set()\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, cls):\n",
        "            names = name.split('.')\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "    if 'lm_head' in lora_module_names:\n",
        "        lora_module_names.remove('lm_head')\n",
        "    print(f\"LoRA module names: {list(lora_module_names)}\")\n",
        "    return list(lora_module_names)\n",
        "\n",
        "def print_trainable_parameters(model, use_4bit = False):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "\n",
        "    :param model: PEFT model\n",
        "    \"\"\"\n",
        "\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "\n",
        "    for _, param in model.named_parameters():\n",
        "        num_params = param.numel()\n",
        "        if num_params == 0 and hasattr(param, \"ds_numel\"):\n",
        "            num_params = param.ds_numel\n",
        "        all_param += num_params\n",
        "        if param.requires_grad:\n",
        "            trainable_params += num_params\n",
        "\n",
        "    if use_4bit:\n",
        "        trainable_params /= 2\n",
        "\n",
        "    print(\n",
        "        f\"All Parameters: {all_param:,d} || Trainable Parameters: {trainable_params:,d} || Trainable Parameters %: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "yLaOGlUa2Aji"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerator = Accelerator()\n",
        "def fine_tune(model,\n",
        "          tokenizer,\n",
        "          dataset,\n",
        "          lora_r,\n",
        "          lora_alpha,\n",
        "          lora_dropout,\n",
        "          bias,\n",
        "          task_type,\n",
        "          per_device_train_batch_size,\n",
        "          gradient_accumulation_steps,\n",
        "          warmup_steps,\n",
        "          max_steps,\n",
        "          learning_rate,\n",
        "          fp16,\n",
        "          logging_steps,\n",
        "          output_dir,\n",
        "          optim):\n",
        "    \"\"\"\n",
        "    Prepares and fine-tune the pre-trained model.\n",
        "\n",
        "    :param model: Pre-trained Hugging Face model\n",
        "    :param tokenizer: Model tokenizer\n",
        "    :param dataset: Preprocessed training dataset\n",
        "    \"\"\"\n",
        "\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "    # Get LoRA module names\n",
        "    target_modules = find_all_linear_names(model)\n",
        "\n",
        "    # Create PEFT configuration for these modules and wrap the model to PEFT\n",
        "    peft_config = create_peft_config(lora_r, lora_alpha, target_modules, lora_dropout, bias, task_type)\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    # Print information about the percentage of trainable parameters\n",
        "    print_trainable_parameters(model)\n",
        "\n",
        "    # Training parameters\n",
        "    trainer = accelerator.prepare(Trainer(\n",
        "        model = model,\n",
        "        train_dataset = dataset,\n",
        "        args = TrainingArguments(\n",
        "            per_device_train_batch_size = per_device_train_batch_size,\n",
        "            gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "            warmup_steps = warmup_steps,\n",
        "            max_steps = max_steps,\n",
        "            learning_rate = learning_rate,\n",
        "            fp16 = fp16,\n",
        "            logging_steps = logging_steps,\n",
        "            output_dir = output_dir,\n",
        "            optim = optim,\n",
        "            report_to = \"none\"\n",
        "        ),\n",
        "        data_collator = DataCollatorForLanguageModeling(tokenizer, mlm = False)\n",
        "    ))\n",
        "\n",
        "    model.config.use_cache = False\n",
        "\n",
        "    do_train = True\n",
        "\n",
        "\n",
        "    print(\"Training...\")\n",
        "\n",
        "    if do_train:\n",
        "        train_result = trainer.train()\n",
        "        metrics = train_result.metrics\n",
        "        trainer.log_metrics(\"train\", metrics)\n",
        "        trainer.save_metrics(\"train\", metrics)\n",
        "        trainer.save_state()\n",
        "        print(metrics)\n",
        "\n",
        "\n",
        "    print(\"Saving last checkpoint of the model...\")\n",
        "    os.makedirs(output_dir, exist_ok = True)\n",
        "    trainer.model.save_pretrained(output_dir)\n",
        "\n",
        "    # Free memory for merging weights\n",
        "    del model\n",
        "    del trainer\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "W7sCVj3G2Alv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# QLoRA parameters\n",
        "# LoRA attention dimension\n",
        "lora_r = 16\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 64\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1\n",
        "\n",
        "\n",
        "bias = \"none\"\n",
        "\n",
        "task_type = \"CAUSAL_LM\"\n",
        "\n",
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 1\n",
        "\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "learning_rate = 2e-4\n",
        "\n",
        "optim = \"paged_adamw_32bit\"\n",
        "max_steps = 20\n",
        "warmup_steps = 2\n",
        "fp16 = True\n",
        "logging_steps = 1"
      ],
      "metadata": {
        "id": "5ESGQ-Z02AoC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune(model, tokenizer, preprocessed_dataset, lora_r, lora_alpha, lora_dropout, bias, task_type, per_device_train_batch_size, gradient_accumulation_steps, warmup_steps, max_steps, learning_rate, fp16, logging_steps, output_dir, optim)"
      ],
      "metadata": {
        "id": "b4pSItxs2Arx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map = \"auto\", torch_dtype = torch.bfloat16)\n",
        "\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "\n",
        "output_merged_dir = \"results/news_classification_llama2_7b/final_merged_checkpoint\"\n",
        "os.makedirs(output_merged_dir, exist_ok = True)\n",
        "model.save_pretrained(output_merged_dir, safe_serialization = True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.save_pretrained(output_merged_dir)"
      ],
      "metadata": {
        "id": "xvp30esW2Atq"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_1 = time()\n",
        "\n",
        "\n",
        "model_name_or_path = '/kaggle/working/results/news_classification_llama2_7b/final_merged_checkpoint'\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    llm_int8_has_fp16_weight=False,\n",
        "\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name_or_path, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "model =  AutoModelForCausalLM.from_pretrained(\n",
        "    model_name_or_path,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True,\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map = 'auto')\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "time_2 = time()\n",
        "print(f\"Time elapsed: {round(time_2-time_1, 3)} sec.\")"
      ],
      "metadata": {
        "id": "K3ts0Zcg2AvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_1 = time()\n",
        "\n",
        "\n",
        "input_text = 'Who is Charlie Brown from Peanuts?'\n",
        "\n",
        "\n",
        "inputs = tokenizer(input_text)\n",
        "inputs = {k: torch.tensor([v]) for k, v in inputs.items()}\n",
        "\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=128, repetition_penalty=1.1)\n",
        "\n",
        "generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(generated_text)\n",
        "\n",
        "time_2 = time()\n",
        "print(f\"Time elapsed: {round(time_2-time_1, 3)} sec.\")"
      ],
      "metadata": {
        "id": "2JLUrq6z3Sho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_1 = time()\n",
        "\n",
        "\n",
        "input_text = 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCategorize the news article description into one of the 42 categories:\\n\\nU.S. NEWS\\nCOMEDY\\nPARENTING\\nWORLD NEWS\\nCULTURE & ARTS\\nTECH\\nSPORTS\\nENTERTAINMENT\\nPOLITICS\\nWEIRD NEWS\\nENVIRONMENT\\nEDUCATION\\nCRIME\\nSCIENCE\\nWELLNESS\\nBUSINESS\\nSTYLE & BEAUTY\\nFOOD & DRINK\\nMEDIA\\nQUEER VOICES\\nHOME & LIVING\\nWOMEN\\nBLACK VOICES\\nTRAVEL\\nMONEY\\nRELIGION\\nLATINO VOICES\\nIMPACT\\nWEDDINGS\\nCOLLEGE\\nPARENTS\\nARTS & CULTURE\\nSTYLE\\nGREEN\\nTASTE\\nHEALTHY LIVING\\nTHE WORLDPOST\\nGOOD NEWS\\nWORLDPOST\\nFIFTY\\nARTS\\nDIVORCE\\n\\nInput:\\nOver 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\\nHealth experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\\n\\n### Response:'\n",
        "\n",
        "\n",
        "inputs = tokenizer(input_text)\n",
        "inputs = {k: torch.tensor([v]) for k, v in inputs.items()}\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=128, repetition_penalty=1.1)\n",
        "\n",
        "generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(generated_text)\n",
        "\n",
        "time_2 = time()\n",
        "print(f\"Time elapsed: {round(time_2-time_1, 3)} sec.\")"
      ],
      "metadata": {
        "id": "z3d78HV53YYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_prompt_formats(dataset[0])['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "iTsaT08t3diP",
        "outputId": "91de171d-28a2-4f9b-a107-79bfe9e65078"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nCategorize the news article description into one of the 42 categories:\\n\\nU.S. NEWS\\nCOMEDY\\nPARENTING\\nWORLD NEWS\\nCULTURE & ARTS\\nTECH\\nSPORTS\\nENTERTAINMENT\\nPOLITICS\\nWEIRD NEWS\\nENVIRONMENT\\nEDUCATION\\nCRIME\\nSCIENCE\\nWELLNESS\\nBUSINESS\\nSTYLE & BEAUTY\\nFOOD & DRINK\\nMEDIA\\nQUEER VOICES\\nHOME & LIVING\\nWOMEN\\nBLACK VOICES\\nTRAVEL\\nMONEY\\nRELIGION\\nLATINO VOICES\\nIMPACT\\nWEDDINGS\\nCOLLEGE\\nPARENTS\\nARTS & CULTURE\\nSTYLE\\nGREEN\\nTASTE\\nHEALTHY LIVING\\nTHE WORLDPOST\\nGOOD NEWS\\nWORLDPOST\\nFIFTY\\nARTS\\nDIVORCE\\n\\nInput:\\nOver 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\\nHealth experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\\n\\n### Response:\\nU.S. NEWS\\n\\n### End'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_end = time()"
      ],
      "metadata": {
        "id": "w_tXfklT3g8D"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}